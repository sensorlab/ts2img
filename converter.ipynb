{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIMESERIES TO IMAGE CONVERTER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilmtk import DataSet\n",
    "import numpy as np\n",
    "\n",
    "from utils.log import print_parameters, print_progress, print_log, print_break, print_end, print_end_of_loop\n",
    "from utils.init import get_appliances, param_setup\n",
    "from utils.file_handling import store_many_hdf5, create_file\n",
    "from utils.data_handling import mount_data, append_images\n",
    "from utils.filters import filter_empty_slices_and_fill_missing_samples, filter_low_entropy_slices\n",
    "from utils.process import transform_ts, moving_window\n",
    "\n",
    "dataset_name = \"iawe\"\n",
    "dataset = DataSet('datasets/'+dataset_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = {\n",
    "    'step_in_mins': 13, # Window size\n",
    "    'max_images': 10, # Number of images per appliance per building.\n",
    "    'img_size': 100, # Output image size.\n",
    "    'frames': 5, # Video frames\n",
    "    'allowed_delta_between_frames': 600*3, # Allowed time difference between frames.\n",
    "    'resample_period': 6, # Resamples time series data to given resample period. Sample period of dataset can be found in dataset.metadata\n",
    "    'fill_limit': 10, # Limit of how many samples to backfill when resampling, larger back fill should yield larger output. \n",
    "    'percentage_of_missing_data_allowed': 0.85, # Missing data will be backfilled.\n",
    "    'add_brightness': True, # Multiply non-zero mean power to image.\n",
    "    'ts_save': False, # Save source time series.\n",
    "    'trs_type': 'GAF', # GAF or RECU - Gramian Angular Field or Recurrance plot.\n",
    "    'trs_type_gaf': 'GASF', # GASF or GADF\n",
    "    'multiple_buildings': True, # If false it processes only one building.\n",
    "    'selected_building': 1, # Used if parameter above is False.\n",
    "    'manually_select_appliances': False # Can be set in get_appliances() function.\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset name:  iawe , date :  2022-03-07 14:52:24  \n",
      " using appliances:  ['washing machine', 'television', 'air conditioner', 'motor', 'computer', 'wet appliance', 'fridge', 'unknown', 'clothes iron'] \n",
      " transtype:  GAF \n",
      " gaf trans type: GASF \n",
      " windows size in mins: 13 \n",
      " image size in pixels: 100 \n",
      " sample period: 6 \n",
      " number if images that are stacked together and in series(series!): 5 \n",
      " allowed max delta between images  1800 \n",
      " added brightness:  True \n",
      " save source timeseries: False \n",
      " manually select appliances: False \n",
      " number of appliances: 9 \n",
      " number of buildings: 1 \n",
      " max number of images per appliance per building: 10 \n",
      " include multiple buildings (Y for Yes N for No): True \n",
      " building selected: A \n",
      "\n",
      "creating new file! ...\n",
      "\n",
      " Starting washing machine (1/9):\n",
      "\n",
      " Starting building 1\n",
      "Finished pre-processing! transforming...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'print_flag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-086ab9d4603d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_stamps\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_stamps_slices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mprint_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_stack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_flag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;31m# Stop if enough data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'print_flag' is not defined"
     ]
    }
   ],
   "source": [
    "# Fixes possible misconfiguration and obtains metadata\n",
    "param_setup(dataset,par)\n",
    "\n",
    "par[\"appliances\"] = get_appliances(dataset,par)\n",
    "print_parameters(par)\n",
    "file_name = create_file(par)\n",
    "\n",
    "# Define global metrics.\n",
    "healthy_appliances = set()\n",
    "images_stacked = 0 \n",
    "images_stacked_per_appliance = 0 \n",
    "\n",
    "# Collect at least \"max_dataset_size\" images for each appliance for every building.\n",
    "for appliance in par[\"appliances\"]:\n",
    "    print_log(par,\"\\n\",\"Starting \"f\"{appliance} (\"f\"{par['appliances'].index(appliance)+1}/\"f\"{len(par['appliances'])}):\")\n",
    "\n",
    "    # Define metric.\n",
    "    images_stacked_per_appliance = 0\n",
    "    \n",
    "    # Loop through all buildings.\n",
    "    for building in dataset.buildings:\n",
    "        print_log(par,\"\\n\",\"Starting building \"f\"{building}\")\n",
    "\n",
    "        # Define temporary array to store image / frames. \n",
    "        img_stack_tmp = np.zeros([0, par[\"img_size\"], par[\"img_size\"]])\n",
    "        sig_stack_tmp = np.zeros([0, par[\"ts_size\"]])\n",
    "        \n",
    "        # Define main array for video to store.\n",
    "        img_stack = np.zeros([0, par[\"frames\"], par[\"img_size\"], par[\"img_size\"]])\n",
    "        sig_stack = np.zeros([0, par[\"frames\"], par[\"ts_size\"]])\n",
    "\n",
    "        # Use only selected building.\n",
    "        if par[\"multiple_buildings\"] == False:\n",
    "            if int(building)  != par[\"selected_building\"]:\n",
    "                print_log(par,\"skipping building \"f\"{building} due to parameter multiple_buildings \")\n",
    "                continue\n",
    "        \n",
    "        # Filter out labels (appliances) with appliance.\n",
    "        for meter in dataset.buildings[building].elec.submeters().meters:  \n",
    "            \n",
    "            # Get appliance name.\n",
    "            label = meter.appliances[0].metadata.get(\"type\")\n",
    "            \n",
    "            # Continue only for appliance from the main loop.\n",
    "            if label != appliance : continue \n",
    "\n",
    "            # Load data into RAM.\n",
    "            signal,time_stamps = mount_data(meter, par)\n",
    "\n",
    "            # Slice time stamps and signal data to specified length.\n",
    "            time_stamps_slices = moving_window(time_stamps, par[\"ts_size\"])\n",
    "            signal_slices = moving_window(signal, par[\"ts_size\"])\n",
    "\n",
    "            # Filter out low entropy data. \n",
    "            signal_slices, time_stamps_slices = filter_empty_slices_and_fill_missing_samples(signal_slices, time_stamps_slices, par)\n",
    "            signal_slices, time_stamps_slices = filter_low_entropy_slices(signal_slices, time_stamps_slices, print_parameters)\n",
    "            \n",
    "            print_log(par,\"Finished pre-processing! transforming...\")\n",
    "\n",
    "            # Continue if no data.\n",
    "            if signal_slices.shape[0] == 0: continue\n",
    "        \n",
    "            # Define metrics.\n",
    "            last_stamp = 0 # Used in append_images for calculating time delta.\n",
    "            next_percent = 10 # Variable helps reduce log output in print_progress().\n",
    "\n",
    "            # Transform pre-processed signal slices. \n",
    "            for i, [sig, time_stamps] in enumerate(zip(signal_slices, time_stamps_slices)):\n",
    "    \n",
    "                next_percent = print_progress(i, signal_slices, img_stack, next_percent, par)\n",
    "\n",
    "                # Stop if enough data.\n",
    "                if img_stack.shape[0] >= par[\"max_images\"]:\n",
    "                    print_log(par,\"max size of \"f\"{par['max_images']} reached, skipping!\")\n",
    "                    break\n",
    "                \n",
    "                sig, img = transform_ts(sig, par)\n",
    "                    \n",
    "                # Append transformed images to stack.\n",
    "                img_stack, img_stack_tmp, sig_stack, sig_stack_tmp, last_stamp = append_images(img, img_stack, img_stack_tmp,\n",
    "                                                                                               sig, sig_stack, sig_stack_tmp,\n",
    "                                                                                               time_stamps, last_stamp, par) \n",
    "        \n",
    "        if img_stack.shape[0] > 0:\n",
    "            # Save images.\n",
    "            group_path = f\"{par['dataset_name']}/\"f\"{appliance}/\"f\"{building}\"\n",
    "            store_many_hdf5(file_name, img_stack[...,np.newaxis], group_path, \"img\", force_del=\"yes\")\n",
    "            \n",
    "            # Update metrics.\n",
    "            images_stacked_per_appliance += img_stack.shape[0]\n",
    "            images_stacked += img_stack.shape[0]\n",
    "            healthy_appliances.add(appliance)\n",
    "            \n",
    "            if par[\"ts_save\"]:\n",
    "                # Save source time series.\n",
    "                store_many_hdf5(file_name, sig_stack, group_path, \"ts\", force_del=\"yes\")\n",
    "        \n",
    "        else:\n",
    "            print_log(par,\"empty for building\", building, \"appliance\", appliance)\n",
    "  \n",
    "        print_log(par, \"finished building N\", building)\n",
    "    \n",
    "    print_end_of_loop(images_stacked_per_appliance, appliance, par)\n",
    "    \n",
    "print_end(images_stacked, healthy_appliances, par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    a = 1.0/0\n",
    "\n",
    "except ValueError:\n",
    "    a = 0\n",
    "\n",
    "except ZeroDivisionError:\n",
    "    a = 0\n",
    "\n",
    "print(a)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
