{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\jjenko\\nilm data\\all\n"
     ]
    }
   ],
   "source": [
    "cd \"nilm data\\all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file.close()\n",
    "file2.close()\n",
    "#file_read.close()\n",
    "file_name = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name= \"eco_H_RESMPL_RECU_13m_100S5X_13A5000N_AB_N-O_Y-S_AVG-N\"\n",
    "#file_name = \"eco_H_GAF_13m_100S5X_13A37099N_AB_N-O_Y-S_AVG-Y\"\n",
    "\n",
    "#file_name = \"refit_H_par_RECU_13m_100S5X_10A5000N_AB_N-O_Y-S_AVG-N-FRIDGE\"\n",
    "#file_name = \"ukdale_H_RECU_13m_100S5X_14A5000N_AB_N-O_Y-S_AVG-N\"\n",
    "#file = h5py.File(\"D:/jjenko/nilm data/GAF_DS/\"f\"{file_name}\"\"/\"f\"{file_name}\"\".hdf5\",\"r\")\n",
    "#file = h5py.File(\"D:/jjenko/nilm data/GAF_DS/\"f\"{file_name}\"\".hdf5\",\"r\")\n",
    "\n",
    "#file_name = \"ALL_13m_130S5X_RECU_AVG-N\"\n",
    "#file_name = \"ALL_13m_100S5X_GDAF_AVG-Y\"\n",
    "file_name = \"ALL_13m_100S5X_GDAF_AVG-Y\"\n",
    "file_name = \"refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name2 = \"ukdale_H_short_GAF_13m_100S5X_3A15023N_AB_N-O_Y-S_AVG-Y\"\n",
    "\n",
    "#donefile_name2 = \"eco_H_short_nonoise_GAF_13m_100S5X_2A1360N_AB_N-O_Y-S_AVG-Y\"\n",
    "#donefile_name2 = \"redd_H_short_GAF_13m_100S5X_1A231N_AB_N-O_Y-S_AVG-Y\"\n",
    "\n",
    "#done file_name2 = \"eco_H_GAF_13m_100S5X_13A37099N_AB_N-O_Y-S_AVG-Y\"\n",
    "#file_name2 = \"refit_H_GAF_13m_100S5X_22A147955N_AB_N-O_Y-S_AVG-Y\"\n",
    "#donefile_name2 = \"redd_H_GAF_13m_100S5X_5A4896N_AB_N-O_Y-S_AVG-Y\"\n",
    "#donefile_name2 = \"iawe_H_GAF_13m_100S5X_5A1547N_AB_N-O_Y-S_AVG-Y\"\n",
    "#donefile_name2 = \"ukdale_H_GAF_13m_100S5X_14A40320N_AB_N-O_Y-S_AVG-Y\"\n",
    "\n",
    "\n",
    "f_names_to_add = [\"redd_H_RSMPL_RECU_13m_100S5X_12A4838N_AB_N-O_Y-S_AVG-N\",\n",
    "\"redd_H_RSMPL_SHORT_RECU_13m_100S5X_1A275N_AB_N-O_Y-S_AVG-N\",\n",
    "\"iawe_H_RSMPL_RECU_13m_100S5X_5A1542N_AB_N-O_Y-S_AVG-N\",\n",
    "\"ukdale_H_RECU_13m_100S5X_14A5000N_AB_N-O_Y-S_AVG-N\",\n",
    "\"ukdale_H_RSMPL_2_2_RECU_13m_100S5X_7A15849N_AB_N-O_Y-S_AVG-N\",\n",
    "\"ukdale_H_RSMPL_SHORT_RECU_13m_100S5X_3A4457N_AB_N-O_Y-S_AVG-N\",\n",
    "\"refit_H_RECU_13m_100S5X_10A5000N_AB_N-O_Y-S_AVG-N_TVandWASHINGMACHINE\",\n",
    "\"refit_H_par_RECU_13m_100S5X_10A5000N_AB_N-O_Y-S_AVG-N-FRIDGE\",\n",
    "\"refit_H_RSMPL_2_2_RECU_13m_100S5X_8A9494N_AB_N-O_Y-S_AVG-N\",\n",
    "\"refit_H_PAR_RSMPL_2_2_RECU_13m_100S5X_9A2258N_AB_N-O_Y-S_AVG-N\",\n",
    "\"refit_H_RSMPL_SHORT_RECU_13m_100S5X_3A12344N_AB_N-O_Y-S_AVG-N\",\n",
    "\n",
    "\"eco_H_RSMPL_RECU_13m_100S5X_13A36886N_AB_N-O_Y-S_AVG-N\",\n",
    "\"eco_H_RSMPL_SHORT_RECU_13m_100S5X_2A1403N_AB_N-O_Y-S_AVG-N\"\n",
    "]\n",
    "\n",
    "f_names_to_add = [\"refit_H_RSMPL_1_GADF_13m_100S5X_10AN42449_AB_N-O_Y-S_AVG-Y\",\n",
    "\"refit_H_RSMPL_2_GADF_13m_100S5X_10A19657N_AB_N-O_Y-S_AVG-Y\",\n",
    "\"refit_H_RSMPL_SHORT_GADF_13m_100S5X_3A30485N_AB_N-O_Y-S_AVG-Y\",\n",
    "\n",
    "\"ukdale_H_RSMPL_GADF_13m_100S5X_14A47274N_AB_N-O_Y-S_AVG-Y\",\n",
    "\"ukdale_H_RSMPL_SHORT_GADF_13m_100S5X_3A17300N_AB_N-O_Y-S_AVG-Y\",\n",
    "\n",
    "\"redd_H_RSMPL_GADF_13m_100S5X_12A4848N_AB_N-O_Y-S_AVG-Y\",\n",
    "\"redd_H_RSMPL_SHORT_GADF_13m_100S5X_1A275N_AB_N-O_Y-S_AVG-Y\",\n",
    "\n",
    "\"eco_H_RSMPL_GADF_13m_100S5X_13A36892N_AB_N-O_Y-S_AVG-Y\",\n",
    "\"eco_H_RSMPL_SHORT_GADF_13m_100S5X_2A1440N_AB_N-O_Y-S_AVG-Y\",\n",
    "\n",
    "\"iawe_H_RSMPL_GADF_13m_100S5X_6A1547N_AB_N-O_Y-S_AVG-Y\",\n",
    "]\n",
    "\n",
    "f_names_to_add = [\n",
    "\"refit_H_GAF_13m_100S5X_22A147955N_AB_N-O_Y-S_AVG-Y\",\n",
    "\"refit_H_short_GAF_13m_100S5X_3A15023N_AB_N-O_Y-S_AVG-Y\",\n",
    "\n",
    "\"ukdale_H_GAF_13m_100S5X_14A40320N_AB_N-O_Y-S_AVG-Y\",\n",
    "\"ukdale_H_short_GAF_13m_100S5X_3A15023N_AB_N-O_Y-S_AVG-Y\",\n",
    "\n",
    "\"redd_H_RSMPL_GASF_13m_100S5X_12A4848N_AB_N-O_Y-S_AVG-Y\",\n",
    "\"redd_H_RSMPL_SHORT_GASF_13m_100S5X_1A275N_AB_N-O_Y-S_AVG-Y\",\n",
    "\n",
    "\"iawe_H_RSMPL_GASF_13m_100S5X_6A1547N_AB_N-O_Y-S_AVG-Y\",\n",
    "\n",
    "\"eco_H_RSMPL_GASF_13m_100S5X_13A36892N_AB_N-O_Y-S_AVG-Y\",\n",
    "\"eco_H_RSMPL_SHORT_GASF_13m_100S5X_2A1400N_AB_N-O_Y-S_AVG-Y\"\n",
    "]\n",
    "\n",
    "f_names_to_add = [\n",
    "\"refit_H_par2_GASF_60m_300S0X_13A1000N_AB_N-O_Y-S_AVG-Y\",\n",
    "\"refit_H_par3_GASF_60m_300S0X_6A1000N_AB_N-O_Y-S_AVG-Y\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appending: refit_H_par2_GASF_60m_300S0X_13A1000N_AB_N-O_Y-S_AVG-Y\n",
      "meta:  refit appliance  buil no  20  len  1000\n",
      "saving to: refit/appliance/20\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/appliance/20/gaf\n",
      "meta:  refit audio system  buil no  11  len  1000\n",
      "saving to: refit/audio system/11\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/audio system/11/gaf\n",
      "meta:  refit audio system  buil no  14  len  1000\n",
      "saving to: refit/audio system/14\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/audio system/14/gaf\n",
      "meta:  refit audio system  buil no  18  len  281\n",
      "saving to: refit/audio system/18\n",
      "storing... samples to store: 281\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/audio system/18/gaf\n",
      "meta:  refit audio system  buil no  2  len  1000\n",
      "saving to: refit/audio system/2\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/audio system/2/gaf\n",
      "meta:  refit audio system  buil no  9  len  96\n",
      "saving to: refit/audio system/9\n",
      "storing... samples to store: 96\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/audio system/9/gaf\n",
      "meta:  refit breadmaker  buil no  18  len  974\n",
      "saving to: refit/breadmaker/18\n",
      "storing... samples to store: 974\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/breadmaker/18/gaf\n",
      "meta:  refit broadband router  buil no  11  len  7\n",
      "saving to: refit/broadband router/11\n",
      "storing... samples to store: 7\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/broadband router/11/gaf\n",
      "meta:  refit broadband router  buil no  13  len  1000\n",
      "saving to: refit/broadband router/13\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/broadband router/13/gaf\n",
      "meta:  refit dehumidifier  buil no  15  len  1000\n",
      "saving to: refit/dehumidifier/15\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/dehumidifier/15/gaf\n",
      "meta:  refit electric space heater  buil no  1  len  1000\n",
      "saving to: refit/electric space heater/1\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/electric space heater/1/gaf\n",
      "meta:  refit electric space heater  buil no  15  len  754\n",
      "saving to: refit/electric space heater/15\n",
      "storing... samples to store: 754\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/electric space heater/15/gaf\n",
      "meta:  refit electric space heater  buil no  9  len  227\n",
      "saving to: refit/electric space heater/9\n",
      "storing... samples to store: 227\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/electric space heater/9/gaf\n",
      "meta:  refit fan  buil no  2  len  218\n",
      "saving to: refit/fan/2\n",
      "storing... samples to store: 218\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fan/2/gaf\n",
      "meta:  refit food processor  buil no  10  len  1000\n",
      "saving to: refit/food processor/10\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/food processor/10/gaf\n",
      "meta:  refit food processor  buil no  20  len  39\n",
      "saving to: refit/food processor/20\n",
      "storing... samples to store: 39\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/food processor/20/gaf\n",
      "meta:  refit fridge freezer  buil no  10  len  1000\n",
      "saving to: refit/fridge freezer/10\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge freezer/10/gaf\n",
      "meta:  refit fridge freezer  buil no  11  len  1000\n",
      "saving to: refit/fridge freezer/11\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge freezer/11/gaf\n",
      "meta:  refit fridge freezer  buil no  12  len  1000\n",
      "saving to: refit/fridge freezer/12\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge freezer/12/gaf\n",
      "meta:  refit fridge freezer  buil no  14  len  1000\n",
      "saving to: refit/fridge freezer/14\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge freezer/14/gaf\n",
      "meta:  refit fridge freezer  buil no  15  len  1000\n",
      "saving to: refit/fridge freezer/15\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge freezer/15/gaf\n",
      "meta:  refit fridge freezer  buil no  16  len  1000\n",
      "saving to: refit/fridge freezer/16\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge freezer/16/gaf\n",
      "meta:  refit fridge freezer  buil no  17  len  1000\n",
      "saving to: refit/fridge freezer/17\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge freezer/17/gaf\n",
      "meta:  refit fridge freezer  buil no  18  len  1000\n",
      "saving to: refit/fridge freezer/18\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge freezer/18/gaf\n",
      "meta:  refit fridge freezer  buil no  2  len  1000\n",
      "saving to: refit/fridge freezer/2\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge freezer/2/gaf\n",
      "meta:  refit fridge freezer  buil no  20  len  1000\n",
      "saving to: refit/fridge freezer/20\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge freezer/20/gaf\n",
      "meta:  refit fridge freezer  buil no  3  len  1000\n",
      "saving to: refit/fridge freezer/3\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge freezer/3/gaf\n",
      "meta:  refit fridge freezer  buil no  4  len  1000\n",
      "saving to: refit/fridge freezer/4\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge freezer/4/gaf\n",
      "meta:  refit fridge freezer  buil no  5  len  1000\n",
      "saving to: refit/fridge freezer/5\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge freezer/5/gaf\n",
      "meta:  refit fridge freezer  buil no  9  len  1000\n",
      "saving to: refit/fridge freezer/9\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge freezer/9/gaf\n",
      "meta:  refit games console  buil no  18  len  876\n",
      "saving to: refit/games console/18\n",
      "storing... samples to store: 876\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/games console/18/gaf\n",
      "meta:  refit pond pump  buil no  20  len  1000\n",
      "saving to: refit/pond pump/20\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/pond pump/20/gaf\n",
      "meta:  refit tumble dryer  buil no  14  len  253\n",
      "saving to: refit/tumble dryer/14\n",
      "storing... samples to store: 253\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/tumble dryer/14/gaf\n",
      "meta:  refit tumble dryer  buil no  16  len  151\n",
      "saving to: refit/tumble dryer/16\n",
      "storing... samples to store: 151\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/tumble dryer/16/gaf\n",
      "meta:  refit tumble dryer  buil no  19  len  463\n",
      "saving to: refit/tumble dryer/19\n",
      "storing... samples to store: 463\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/tumble dryer/19/gaf\n",
      "meta:  refit tumble dryer  buil no  20  len  372\n",
      "saving to: refit/tumble dryer/20\n",
      "storing... samples to store: 372\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/tumble dryer/20/gaf\n",
      "meta:  refit tumble dryer  buil no  3  len  1000\n",
      "saving to: refit/tumble dryer/3\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/tumble dryer/3/gaf\n",
      "meta:  refit tumble dryer  buil no  4  len  152\n",
      "saving to: refit/tumble dryer/4\n",
      "storing... samples to store: 152\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/tumble dryer/4/gaf\n",
      "meta:  refit tumble dryer  buil no  5  len  1000\n",
      "saving to: refit/tumble dryer/5\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/tumble dryer/5/gaf\n",
      "meta:  refit tumble dryer  buil no  7  len  1000\n",
      "saving to: refit/tumble dryer/7\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/tumble dryer/7/gaf\n",
      "meta:  refit unknown  buil no  12  len  1000\n",
      "saving to: refit/unknown/12\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/unknown/12/gaf\n",
      "meta:  refit unknown  buil no  13  len  480\n",
      "saving to: refit/unknown/13\n",
      "storing... samples to store: 480\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/unknown/13/gaf\n",
      "meta:  refit unknown  buil no  20  len  860\n",
      "saving to: refit/unknown/20\n",
      "storing... samples to store: 860\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/unknown/20/gaf\n",
      "appending: refit_H_par3_GASF_60m_300S0X_6A1000N_AB_N-O_Y-S_AVG-Y\n",
      "meta:  refit computer  buil no  1  len  1000\n",
      "saving to: refit/computer/1\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/computer/1/gaf\n",
      "meta:  refit computer  buil no  11  len  438\n",
      "saving to: refit/computer/11\n",
      "storing... samples to store: 438\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/computer/11/gaf\n",
      "meta:  refit computer  buil no  12  len  1000\n",
      "saving to: refit/computer/12\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/computer/12/gaf\n",
      "meta:  refit computer  buil no  14  len  652\n",
      "saving to: refit/computer/14\n",
      "storing... samples to store: 652\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/computer/14/gaf\n",
      "meta:  refit computer  buil no  15  len  1000\n",
      "saving to: refit/computer/15\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/computer/15/gaf\n",
      "meta:  refit computer  buil no  16  len  1000\n",
      "saving to: refit/computer/16\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/computer/16/gaf\n",
      "meta:  refit computer  buil no  17  len  1000\n",
      "saving to: refit/computer/17\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/computer/17/gaf\n",
      "meta:  refit computer  buil no  19  len  1000\n",
      "saving to: refit/computer/19\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/computer/19/gaf\n",
      "meta:  refit computer  buil no  5  len  1000\n",
      "saving to: refit/computer/5\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/computer/5/gaf\n",
      "meta:  refit computer  buil no  6  len  1000\n",
      "saving to: refit/computer/6\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/computer/6/gaf\n",
      "meta:  refit computer  buil no  8  len  1000\n",
      "saving to: refit/computer/8\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/computer/8/gaf\n",
      "meta:  refit dish washer  buil no  1  len  315\n",
      "saving to: refit/dish washer/1\n",
      "storing... samples to store: 315\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/dish washer/1/gaf\n",
      "meta:  refit dish washer  buil no  10  len  1000\n",
      "saving to: refit/dish washer/10\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/dish washer/10/gaf\n",
      "meta:  refit dish washer  buil no  11  len  216\n",
      "saving to: refit/dish washer/11\n",
      "storing... samples to store: 216\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/dish washer/11/gaf\n",
      "meta:  refit dish washer  buil no  13  len  364\n",
      "saving to: refit/dish washer/13\n",
      "storing... samples to store: 364\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/dish washer/13/gaf\n",
      "meta:  refit dish washer  buil no  14  len  138\n",
      "saving to: refit/dish washer/14\n",
      "storing... samples to store: 138\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/dish washer/14/gaf\n",
      "meta:  refit dish washer  buil no  15  len  649\n",
      "saving to: refit/dish washer/15\n",
      "storing... samples to store: 649\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/dish washer/15/gaf\n",
      "meta:  refit dish washer  buil no  17  len  441\n",
      "saving to: refit/dish washer/17\n",
      "storing... samples to store: 441\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/dish washer/17/gaf\n",
      "meta:  refit dish washer  buil no  19  len  351\n",
      "saving to: refit/dish washer/19\n",
      "storing... samples to store: 351\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/dish washer/19/gaf\n",
      "meta:  refit dish washer  buil no  2  len  1000\n",
      "saving to: refit/dish washer/2\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/dish washer/2/gaf\n",
      "meta:  refit dish washer  buil no  20  len  981\n",
      "saving to: refit/dish washer/20\n",
      "storing... samples to store: 981\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/dish washer/20/gaf\n",
      "meta:  refit dish washer  buil no  3  len  1000\n",
      "saving to: refit/dish washer/3\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/dish washer/3/gaf\n",
      "meta:  refit dish washer  buil no  5  len  1000\n",
      "saving to: refit/dish washer/5\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/dish washer/5/gaf\n",
      "meta:  refit dish washer  buil no  6  len  307\n",
      "saving to: refit/dish washer/6\n",
      "storing... samples to store: 307\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/dish washer/6/gaf\n",
      "meta:  refit dish washer  buil no  7  len  1000\n",
      "saving to: refit/dish washer/7\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/dish washer/7/gaf\n",
      "meta:  refit dish washer  buil no  9  len  1000\n",
      "saving to: refit/dish washer/9\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/dish washer/9/gaf\n",
      "meta:  refit fridge  buil no  1  len  1000\n",
      "saving to: refit/fridge/1\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge/1/gaf\n",
      "meta:  refit fridge  buil no  11  len  1000\n",
      "saving to: refit/fridge/11\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge/11/gaf\n",
      "meta:  refit fridge  buil no  17  len  1000\n",
      "saving to: refit/fridge/17\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge/17/gaf\n",
      "meta:  refit fridge  buil no  19  len  1000\n",
      "saving to: refit/fridge/19\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge/19/gaf\n",
      "meta:  refit fridge  buil no  4  len  1000\n",
      "saving to: refit/fridge/4\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge/4/gaf\n",
      "meta:  refit fridge  buil no  7  len  1000\n",
      "saving to: refit/fridge/7\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge/7/gaf\n",
      "meta:  refit fridge  buil no  8  len  1000\n",
      "saving to: refit/fridge/8\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/fridge/8/gaf\n",
      "meta:  refit television  buil no  1  len  1000\n",
      "saving to: refit/television/1\n",
      "  removed gaf!\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/1/gaf\n",
      "meta:  refit television  buil no  10  len  1000\n",
      "saving to: refit/television/10\n",
      "  removed gaf!\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/10/gaf\n",
      "meta:  refit television  buil no  13  len  651\n",
      "saving to: refit/television/13\n",
      "  removed gaf!\n",
      "storing... samples to store: 651\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/13/gaf\n",
      "meta:  refit television  buil no  14  len  1000\n",
      "saving to: refit/television/14\n",
      "  removed gaf!\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/14/gaf\n",
      "meta:  refit television  buil no  15  len  1000\n",
      "saving to: refit/television/15\n",
      "  removed gaf!\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/15/gaf\n",
      "meta:  refit television  buil no  16  len  1000\n",
      "saving to: refit/television/16\n",
      "  removed gaf!\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/16/gaf\n",
      "meta:  refit television  buil no  17  len  1000\n",
      "saving to: refit/television/17\n",
      "  removed gaf!\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/17/gaf\n",
      "meta:  refit television  buil no  18  len  1000\n",
      "saving to: refit/television/18\n",
      "  removed gaf!\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/18/gaf\n",
      "meta:  refit television  buil no  19  len  1000\n",
      "saving to: refit/television/19\n",
      "  removed gaf!\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/19/gaf\n",
      "meta:  refit television  buil no  2  len  1000\n",
      "saving to: refit/television/2\n",
      "  removed gaf!\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/2/gaf\n",
      "meta:  refit television  buil no  20  len  1000\n",
      "saving to: refit/television/20\n",
      "  removed gaf!\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/20/gaf\n",
      "meta:  refit television  buil no  3  len  1000\n",
      "saving to: refit/television/3\n",
      "  removed gaf!\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/3/gaf\n",
      "meta:  refit television  buil no  4  len  1000\n",
      "saving to: refit/television/4\n",
      "  removed gaf!\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/4/gaf\n",
      "meta:  refit television  buil no  5  len  1000\n",
      "saving to: refit/television/5\n",
      "  removed gaf!\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/5/gaf\n",
      "meta:  refit television  buil no  6  len  1000\n",
      "saving to: refit/television/6\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/6/gaf\n",
      "meta:  refit television  buil no  7  len  1000\n",
      "saving to: refit/television/7\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/7/gaf\n",
      "meta:  refit television  buil no  8  len  1000\n",
      "saving to: refit/television/8\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/8/gaf\n",
      "meta:  refit television  buil no  9  len  1000\n",
      "saving to: refit/television/9\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/television/9/gaf\n",
      "meta:  refit toaster  buil no  10  len  1000\n",
      "saving to: refit/toaster/10\n",
      "  removed gaf!\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/toaster/10/gaf\n",
      "meta:  refit toaster  buil no  14  len  100\n",
      "saving to: refit/toaster/14\n",
      "  removed gaf!\n",
      "storing... samples to store: 100\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/toaster/14/gaf\n",
      "meta:  refit toaster  buil no  18  len  580\n",
      "saving to: refit/toaster/18\n",
      "  removed gaf!\n",
      "storing... samples to store: 580\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/toaster/18/gaf\n",
      "meta:  refit toaster  buil no  2  len  550\n",
      "saving to: refit/toaster/2\n",
      "  removed gaf!\n",
      "storing... samples to store: 550\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/toaster/2/gaf\n",
      "meta:  refit toaster  buil no  3  len  499\n",
      "saving to: refit/toaster/3\n",
      "  removed gaf!\n",
      "storing... samples to store: 499\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/toaster/3/gaf\n",
      "meta:  refit toaster  buil no  5  len  1000\n",
      "saving to: refit/toaster/5\n",
      "  removed gaf!\n",
      "storing... samples to store: 1000\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/toaster/5/gaf\n",
      "meta:  refit toaster  buil no  6  len  613\n",
      "saving to: refit/toaster/6\n",
      "  removed gaf!\n",
      "storing... samples to store: 613\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/toaster/6/gaf\n",
      "meta:  refit toaster  buil no  7  len  824\n",
      "saving to: refit/toaster/7\n",
      "  removed gaf!\n",
      "storing... samples to store: 824\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/toaster/7/gaf\n",
      "meta:  refit toaster  buil no  8  len  586\n",
      "saving to: refit/toaster/8\n",
      "  removed gaf!\n",
      "storing... samples to store: 586\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/toaster/8/gaf\n",
      "meta:  refit washer dryer  buil no  1  len  455\n",
      "saving to: refit/washer dryer/1\n",
      "storing... samples to store: 455\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/washer dryer/1/gaf\n",
      "meta:  refit washer dryer  buil no  17  len  132\n",
      "saving to: refit/washer dryer/17\n",
      "storing... samples to store: 132\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/washer dryer/17/gaf\n",
      "meta:  refit washer dryer  buil no  8  len  337\n",
      "saving to: refit/washer dryer/8\n",
      "storing... samples to store: 337\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/washer dryer/8/gaf\n",
      "meta:  refit washer dryer  buil no  9  len  914\n",
      "saving to: refit/washer dryer/9\n",
      "storing... samples to store: 914\n",
      "finshed. stored to refit_H_GASF_60m_300S0X_23A6000N_AB_N-O_Y-S_AVG-Y/refit/washer dryer/9/gaf\n"
     ]
    }
   ],
   "source": [
    "## add hier dataset to master hier dataset\n",
    "\n",
    "for file_name2 in f_names_to_add:\n",
    "    print(\"appending:\",file_name2)\n",
    "    file2 = h5py.File(\"D:/jjenko/nilm data/GAF_DS/\"f\"{file_name2}\"\".hdf5\",\"r\")\n",
    "\n",
    "    dataset_appending = file_name2.split(\"_\")[0]\n",
    "    for dataset in file2.keys():\n",
    "        if dataset == dataset_appending:\n",
    "            for appliance in file2[f'{dataset}'].keys():\n",
    "                for building in file2[f'{dataset}'\"/\"f'{appliance}'].keys():\n",
    "                    \n",
    "                    train_data = file2[dataset+\"/\"+appliance+\"/\"+building+\"/gaf\"]\n",
    "                    #print metadata\n",
    "                    print(\"meta: \",dataset,appliance,\" buil no \",building,\" len \",len(train_data))\n",
    "                    group_path = f\"{dataset}\"\"/\"f\"{appliance}\"\"/\"f\"{building}\"\"\"\n",
    "                    print(\"saving to:\",group_path)\n",
    "                    if train_data.shape[0] > 0:\n",
    "                        store_many_hdf5(train_data,group_path,\"gaf\",force_del=\"yes\")\n",
    "                    else:\n",
    "                        print(\"empty for building\",building,\"appliance\",appliance)\n",
    "                    \n",
    "    file2.close()\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available ['air conditioner', 'computer', 'fridge', 'television', 'washing machine']\n",
      "lengts {'air conditioner': [117], 'computer': [678], 'fridge': [1299], 'television': [147], 'washing machine': [1]}\n",
      "instances {'air conditioner': 1, 'computer': 1, 'fridge': 1, 'television': 1, 'washing machine': 1}\n",
      "air conditioner 117\n",
      "computer 678\n",
      "fridge 1299\n",
      "television 147\n",
      "washing machine 1\n",
      "num of samples:  2242\n"
     ]
    }
   ],
   "source": [
    "#check contents of the dataset\n",
    "#appliance_set = set()\n",
    "file_name = \"eco_H_GASF_60m_300S0X_15A6000N_AB_N-O_Y-S_AVG-Y\"\n",
    "#file_name = \"ALL_13m_100S5X_GDAF_AVG-Y\"\n",
    "#file_name = \"iawe_H_GASF_60m_300S0X_6A6000N_AB_N-O_Y-S_AVG-Y\"\n",
    "\n",
    "file = h5py.File(\"D:/jjenko/nilm data/GAF_DS/\"f\"{file_name}\"\".hdf5\",\"r\")\n",
    "\n",
    "\n",
    "appliance_instances = {}\n",
    "all_appliances = []\n",
    "datasets = [\"eco\"]\n",
    "appliances_len = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "      \n",
    "    for appliance in file[dataset].keys():\n",
    "\n",
    "        for building in file[f\"{dataset}\"\"/\"f\"{appliance}\"\"/\"].keys():\n",
    "            all_appliances.append(appliance)\n",
    "            #appliance_set.add(appliance)\n",
    "            \n",
    "            samples = file[f\"{dataset}\"\"/\"f\"{appliance}\"\"/\"f\"{building}\"\"/gaf\"].shape[0]\n",
    "            \n",
    "            if appliance in appliances_len:\n",
    "                appliances_len[appliance].append(samples)#appliances_len[appliance] = appliances_len[appliance]+samples\n",
    "            else:\n",
    "                appliances_len[appliance] = [samples]\n",
    "             \n",
    "#available_appliances = list(appliance_set)\n",
    "available_appliances_arr, instances = np.unique(all_appliances,return_counts=True)\n",
    "available_appliances = list(available_appliances_arr)\n",
    "for i,appliance in enumerate(available_appliances):\n",
    "    appliance_instances[appliance] = instances[i]\n",
    "    \n",
    "print(\"available\",available_appliances)\n",
    "print(\"lengts\",appliances_len)\n",
    "print(\"instances\",appliance_instances)\n",
    "\n",
    "sum_all = 0 \n",
    "N = 2000\n",
    "for e in appliances_len:\n",
    "    print(e,sum(appliances_len[e]))\n",
    "    sum_all += sum(appliances_len[e])\n",
    "print(\"num of samples: \",sum_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = file[dataset+\"/fridge/1/gaf\"]\n",
    "count = 0;\n",
    "count2 = 0;\n",
    "duplicates = set()\n",
    "for i,image in enumerate(a):\n",
    "    for j,image2 in enumerate(a):\n",
    "        if j < i:\n",
    "            continue\n",
    "        if np.all(image == image2):\n",
    "            count = count +1\n",
    "            \n",
    "            if (i != j):\n",
    "                duplicates.add(i)\n",
    "                duplicates.add(j)\n",
    "            \n",
    "            \n",
    "        count2 = count2 +1\n",
    "\n",
    "\n",
    "print(count2,count,a.shape)\n",
    "print(\"dupl:\",duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = file_tmp[\"labels/tmp/gasf\"][:]\n",
    "images =  file_tmp[\"data/tmp/gaf\"]\n",
    "\n",
    "train, test = train_test_split(image_indexes,test_size=0.2,random_state=12,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessed_mapping = map(labels.__getitem__,test)\n",
    "test_labels = list(labels[[test]])\n",
    "for item in list(set(test_labels)):\n",
    "    print(\"item\",item,\"len\",test_labels.count(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-af4ca40a0483>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfile_read\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"iawe/fridge/1/gaf\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "file_read[\"iawe/fridge/1/gaf\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fridge/freezer': ['fridge'],\n",
       " 'electric furnace': ['electric furnace'],\n",
       " 'light': ['light'],\n",
       " 'microwave': ['microwave'],\n",
       " 'sockets': ['sockets']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_appliances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "**appliance stats:\n",
      "HTPC [2142, 94, 1848, 1344, 4153] 9581 avg: 1916\n",
      "air handling unit [224] 224 avg: 224\n",
      "audio system [2226] 2226 avg: 2226\n",
      "broadband router [2037] 2037 avg: 2037\n",
      "coffee maker [226, 37, 844, 456] 1563 avg: 390\n",
      "computer [359, 55, 5117] 5531 avg: 1843\n",
      "dish washer [167] 167 avg: 167\n",
      "freezer [5466, 5644, 1905, 4284] 17299 avg: 4324\n",
      "fridge [4632, 5499, 529, 4419, 5116, 4096] 24291 avg: 4048\n",
      "garden sprinkler [262] 262 avg: 262\n",
      "kettle [358, 269, 25, 3, 81] 736 avg: 147\n",
      "lamp [728, 2061, 54] 2843 avg: 947\n",
      "laptop computer [1321, 2486, 447] 4254 avg: 1418\n",
      "microwave [652, 79] 731 avg: 365\n",
      "washing machine [645] 645 avg: 645\n",
      "num of samples:  72390\n",
      "----------------------------------\n",
      "%  0.7870750961476229\n",
      "eco HTPC 2 (1713, 300, 300, 1) 1713 2 HTPC\n",
      "dataset shape  (1713, 300, 300, 1)\n",
      "label sahape  (1713,)\n",
      "%  0.7870750961476229\n",
      "eco HTPC 3 (75, 300, 300, 1) 75 2 HTPC\n",
      "dataset shape  (1788, 300, 300, 1)\n",
      "label sahape  (1788,)\n",
      "%  0.7870750961476229\n",
      "eco HTPC 4 (1478, 300, 300, 1) 1478 2 HTPC\n",
      "dataset shape  (3266, 300, 300, 1)\n",
      "label sahape  (3266,)\n",
      "%  0.7870750961476229\n",
      "eco HTPC 5 (1075, 300, 300, 1) 1075 2 HTPC\n",
      "dataset shape  (4341, 300, 300, 1)\n",
      "label sahape  (4341,)\n",
      "%  0.7870750961476229\n",
      "eco HTPC 6 (3322, 300, 300, 1) 3322 2 HTPC\n",
      "dataset shape  (7663, 300, 300, 1)\n",
      "label sahape  (7663,)\n",
      "%  0.5832402974242978\n",
      "eco audio system 2 (1780, 300, 300, 1) 1780 3 audio system\n",
      "dataset shape  (9443, 300, 300, 1)\n",
      "label sahape  (9443,)\n",
      "%  0.6964914424337774\n",
      "eco broadband router 6 (1629, 300, 300, 1) 1629 4 broadband router\n",
      "dataset shape  (11072, 300, 300, 1)\n",
      "label sahape  (11072,)\n",
      "%  18.92778827729701\n",
      "eco coffee maker 1 (180, 300, 300, 1) 180 5 coffee maker\n",
      "dataset shape  (11252, 300, 300, 1)\n",
      "label sahape  (11252,)\n",
      "%  18.92778827729701\n",
      "eco coffee maker 3 (29, 300, 300, 1) 29 5 coffee maker\n",
      "dataset shape  (11281, 300, 300, 1)\n",
      "label sahape  (11281,)\n",
      "%  18.92778827729701\n",
      "eco coffee maker 5 (675, 300, 300, 1) 675 5 coffee maker\n",
      "dataset shape  (11956, 300, 300, 1)\n",
      "label sahape  (11956,)\n",
      "%  18.92778827729701\n",
      "eco coffee maker 6 (364, 300, 300, 1) 364 5 coffee maker\n",
      "dataset shape  (12320, 300, 300, 1)\n",
      "label sahape  (12320,)\n",
      "%  0.8502233642361141\n",
      "eco computer 1 (287, 300, 300, 1) 287 6 computer\n",
      "dataset shape  (12607, 300, 300, 1)\n",
      "label sahape  (12607,)\n",
      "%  0.8502233642361141\n",
      "eco computer 3 (44, 300, 300, 1) 44 6 computer\n",
      "dataset shape  (12651, 300, 300, 1)\n",
      "label sahape  (12651,)\n",
      "%  0.8502233642361141\n",
      "eco computer 5 (4093, 300, 300, 1) 4093 6 computer\n",
      "dataset shape  (16744, 300, 300, 1)\n",
      "label sahape  (16744,)\n",
      "%  0.15451684362415233\n",
      "eco freezer 1 (4372, 300, 300, 1) 4372 1 fridge/freezer\n",
      "dataset shape  (21116, 300, 300, 1)\n",
      "label sahape  (21116,)\n",
      "%  0.15451684362415233\n",
      "eco freezer 2 (4515, 300, 300, 1) 4515 1 fridge/freezer\n",
      "dataset shape  (25631, 300, 300, 1)\n",
      "label sahape  (25631,)\n",
      "%  0.15451684362415233\n",
      "eco freezer 3 (1524, 300, 300, 1) 1524 1 fridge/freezer\n",
      "dataset shape  (27155, 300, 300, 1)\n",
      "label sahape  (27155,)\n",
      "%  0.15451684362415233\n",
      "eco freezer 4 (3427, 300, 300, 1) 3427 1 fridge/freezer\n",
      "dataset shape  (30582, 300, 300, 1)\n",
      "label sahape  (30582,)\n",
      "%  0.17632323917870646\n",
      "eco fridge 1 (3705, 300, 300, 1) 3705 1 fridge/freezer\n",
      "dataset shape  (34287, 300, 300, 1)\n",
      "label sahape  (34287,)\n",
      "%  0.17632323917870646\n",
      "eco fridge 2 (4399, 300, 300, 1) 4399 1 fridge/freezer\n",
      "dataset shape  (38686, 300, 300, 1)\n",
      "label sahape  (38686,)\n",
      "%  0.17632323917870646\n",
      "eco fridge 3 (423, 300, 300, 1) 423 1 fridge/freezer\n",
      "dataset shape  (39109, 300, 300, 1)\n",
      "label sahape  (39109,)\n",
      "%  0.17632323917870646\n",
      "eco fridge 4 (3535, 300, 300, 1) 3535 1 fridge/freezer\n",
      "dataset shape  (42644, 300, 300, 1)\n",
      "label sahape  (42644,)\n",
      "%  0.17632323917870646\n",
      "eco fridge 5 (4092, 300, 300, 1) 4092 1 fridge/freezer\n",
      "dataset shape  (46736, 300, 300, 1)\n",
      "label sahape  (46736,)\n",
      "%  0.17632323917870646\n",
      "eco fridge 6 (3276, 300, 300, 1) 3276 1 fridge/freezer\n",
      "dataset shape  (50012, 300, 300, 1)\n",
      "label sahape  (50012,)\n",
      "%  133.37739248582233\n",
      "eco kettle 1 (286, 300, 300, 1) 286 0 HEKA\n",
      "dataset shape  (50298, 300, 300, 1)\n",
      "label sahape  (50298,)\n",
      "%  133.37739248582233\n",
      "eco kettle 2 (215, 300, 300, 1) 215 0 HEKA\n",
      "dataset shape  (50513, 300, 300, 1)\n",
      "label sahape  (50513,)\n",
      "%  133.37739248582233\n",
      "eco kettle 3 (20, 300, 300, 1) 20 0 HEKA\n",
      "dataset shape  (50533, 300, 300, 1)\n",
      "label sahape  (50533,)\n",
      "%  133.37739248582233\n",
      "eco kettle 5 (2, 300, 300, 1) 2 0 HEKA\n",
      "dataset shape  (50535, 300, 300, 1)\n",
      "label sahape  (50535,)\n",
      "%  133.37739248582233\n",
      "eco kettle 6 (64, 300, 300, 1) 64 0 HEKA\n",
      "dataset shape  (50599, 300, 300, 1)\n",
      "label sahape  (50599,)\n",
      "%  3.2180043943514067\n",
      "eco lamp 2 (582, 300, 300, 1) 582 7 lamp\n",
      "dataset shape  (51181, 300, 300, 1)\n",
      "label sahape  (51181,)\n",
      "%  3.2180043943514067\n",
      "eco lamp 4 (1648, 300, 300, 1) 1648 7 lamp\n",
      "dataset shape  (52829, 300, 300, 1)\n",
      "label sahape  (52829,)\n",
      "%  3.2180043943514067\n",
      "eco lamp 6 (43, 300, 300, 1) 43 7 lamp\n",
      "dataset shape  (52872, 300, 300, 1)\n",
      "label sahape  (52872,)\n",
      "%  1.4372932336810023\n",
      "eco laptop computer 2 (1056, 300, 300, 1) 1056 8 laptop computer\n",
      "dataset shape  (53928, 300, 300, 1)\n",
      "label sahape  (53928,)\n",
      "%  1.4372932336810023\n",
      "eco laptop computer 4 (1988, 300, 300, 1) 1988 8 laptop computer\n",
      "dataset shape  (55916, 300, 300, 1)\n",
      "label sahape  (55916,)\n",
      "%  1.4372932336810023\n",
      "eco laptop computer 6 (357, 300, 300, 1) 357 8 laptop computer\n",
      "dataset shape  (56273, 300, 300, 1)\n",
      "label sahape  (56273,)\n",
      "%  21.63331530557058\n",
      "eco microwave 4 (521, 300, 300, 1) 521 9 microwave\n",
      "dataset shape  (56794, 300, 300, 1)\n",
      "label sahape  (56794,)\n",
      "%  21.63331530557058\n",
      "eco microwave 5 (63, 300, 300, 1) 63 9 microwave\n",
      "dataset shape  (56857, 300, 300, 1)\n",
      "label sahape  (56857,)\n",
      "%  6.946697914788774\n",
      "eco washing machine 1 (516, 300, 300, 1) 516 10 washing machine\n",
      "dataset shape  (57373, 300, 300, 1)\n",
      "label sahape  (57373,)\n",
      "finished size 57373\n",
      "unique labels  [{'HEKA': ['kettle'], 'fridge/freezer': ['fridge', 'freezer'], 'HTPC': ['HTPC'], 'audio system': ['audio system'], 'broadband router': ['broadband router'], 'coffee maker': ['coffee maker'], 'computer': ['computer'], 'lamp': ['lamp'], 'laptop computer': ['laptop computer'], 'microwave': ['microwave'], 'washing machine': ['washing machine']}] n 11\n",
      "counts (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
      "      dtype=float32), array([  587, 33268,  7663,  1780,  1629,  1248,  4424,  2273,  3401,\n",
      "         584,   516], dtype=int64))\n",
      "----------------------------------\n",
      "storing [b'HEKA', b'fridge/freezer', b'HTPC', b'audio system', b'broadband router', b'coffee maker', b'computer', b'lamp', b'laptop computer', b'microwave', b'washing machine'] n appl 11\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "#load hier dataset and save it as generator ready (split into test train)\n",
    "file_name_read = \"eco_H_GASF_60m_300S0X_15A6000N_AB_N-O_Y-S_AVG-Y\"\n",
    "file_read = h5py.File(\"D:/jjenko/nilm data/GAF_DS/\"f\"{file_name_read}\"\".hdf5\",\"r\")\n",
    "\n",
    "N_wanted = 1700\n",
    "\n",
    "#dataset\n",
    "datasets = [\"eco\"]\n",
    "\n",
    "#file name to write to!\n",
    "file_name_tmp = datasets[0]+\"_gen_GASF_60m_300S0X_2\"\n",
    "\n",
    "images = np.zeros([0, 300, 300, 1])\n",
    "labels = np.zeros(0)\n",
    "labels_building = np.zeros(0)\n",
    "labels_dataset = np.zeros(0)\n",
    "\n",
    "#group for data\n",
    "data_path = \"data\"\n",
    "label_path = \"labels\"\n",
    "\n",
    "#classes\n",
    "file_tmp = h5py.File(\"D:/jjenko/nilm data/GAF_DS/\"f\"{file_name_tmp}\"\".hdf5\", \"a\")\n",
    "\n",
    "counter1 = 0\n",
    "last_appliance1 = 0\n",
    "counter2 = 0\n",
    "last_appliance2 = 0\n",
    "HEKA = []\n",
    "FF = []\n",
    "# del file[\"data/tmp/gaf\"]\n",
    "# del file[\"labels/tmp/gasf\"]\n",
    "try:\n",
    "    group_data = file_tmp[\"data/\"]\n",
    "except:\n",
    "    #if if does not exist create it\n",
    "    group_data = file_tmp.create_group(\"data/\")\n",
    "\n",
    "try:\n",
    "    group_labels = file_tmp[\"labels/\"]\n",
    "except:\n",
    "    #if if does not exist create it\n",
    "    group_labels = file_tmp.create_group(\"labels/\")\n",
    "    \n",
    "try:\n",
    "    dataset1 = group_data.create_dataset(\"gaf\", np.shape(images),h5py.h5t.IEEE_F32LE,maxshape=(None,300,300,1), chunks=True)\n",
    "    dataset2 = group_labels.create_dataset(\"gaf\", np.shape(labels),h5py.h5t.IEEE_F32LE,maxshape=(None,) ,chunks=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#get unique datasets and apliances from dataset for indexing\n",
    "all_appliances = []\n",
    "appliances_len = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    for appliance in file_read[f'{dataset}'].keys():\n",
    "        for building in file_read[f'{dataset}'\"/\"f'{appliance}'].keys():\n",
    "            all_appliances.append(appliance)\n",
    "\n",
    "            samples = file_read[f\"{dataset}\"\"/\"f\"{appliance}\"\"/\"f\"{building}\"\"/gaf\"].shape[0]\n",
    "            #print(samples)\n",
    "            if appliance in appliances_len:\n",
    "                appliances_len[appliance].append(samples)#appliances_len[appliance] = appliances_len[appliance]+samples\n",
    "            else:\n",
    "                appliances_len[appliance] = [samples]\n",
    "           \n",
    "\n",
    "available_appliances_arr, instances = np.unique(all_appliances,return_counts=True)\n",
    "available_appliances = list(available_appliances_arr)\n",
    "print(\"----------------------------------\")\n",
    "print(\"**appliance stats:\")\n",
    "sum_all = 0 \n",
    "for e in appliances_len:\n",
    "    print(e,appliances_len[e],sum(appliances_len[e]),\"avg:\",int(statistics.mean(appliances_len[e])))\n",
    "    sum_all += sum(appliances_len[e])\n",
    "print(\"num of samples: \",sum_all)\n",
    "print(\"----------------------------------\")\n",
    "\n",
    "grouped_appliances = get_grouped_appliances(available_appliances,datasets)\n",
    "\n",
    "appliances = list(grouped_appliances)\n",
    "\n",
    "for dataset in datasets:\n",
    "    for appliance in file_read[f'{dataset}'].keys():\n",
    "\n",
    "        if appliance in sum(list(grouped_appliances.values()),[]):\n",
    "            \n",
    "            index = None\n",
    "            for i,e in enumerate(list(grouped_appliances.values())):\n",
    "                if appliance in e:\n",
    "                #print(\"ok\",i)\n",
    "                    index = i\n",
    "    \n",
    "            grouped_appliance = list(grouped_appliances.keys())[index]\n",
    "\n",
    "\n",
    "            for building in file_read[f'{dataset}'\"/\"f'{appliance}'].keys():\n",
    "                \n",
    "                images = file_read[dataset+\"/\"+appliance+\"/\"+building+\"/gaf\"]\n",
    "\n",
    "                samples = images.shape[0]\n",
    "                N = N_wanted/statistics.mean(appliances_len[appliance])\n",
    "                print(\"% \",N*N)\n",
    "\n",
    "                N = int(N*N*samples)\n",
    "                N = int(samples*0.8)\n",
    "            \n",
    "                # if N > N_wanted:\n",
    "                #     N = N_wanted\n",
    "\n",
    "                if appliance in HEKA:\n",
    "\n",
    "                    N = int(N/len(HEKA))\n",
    "                \n",
    "                if appliance in FF:\n",
    "                \n",
    "                    N = int(N/len(FF))\n",
    "                    \n",
    "        \n",
    "                images = file_read[dataset+\"/\"+appliance+\"/\"+building+\"/gaf\"][0:N]\n",
    "                \n",
    "                print(dataset,appliance,building,images.shape,N,list(grouped_appliances.keys()).index(grouped_appliance),grouped_appliance)\n",
    "\n",
    "                file_tmp['data/gaf'].resize((file_tmp['data/gaf'].shape[0] + images.shape[0]), axis=0)\n",
    "                file_tmp['data/gaf'][-images.shape[0]:] = images\n",
    "                \n",
    "                #labels = np.ones(images.shape[0])*appliances_list.index(appliance)\n",
    "                labels = np.ones(images.shape[0])*list(grouped_appliances.keys()).index(grouped_appliance)\n",
    "                file_tmp['labels/gaf'].resize((file_tmp['labels/gaf'].shape[0] + labels.shape[0]), axis=0)\n",
    "                file_tmp['labels/gaf'][-labels.shape[0]:] = labels\n",
    "                \n",
    "                print(\"dataset shape \",file_tmp['data/gaf'].shape)\n",
    "                print(\"label sahape \",file_tmp['labels/gaf'].shape)\n",
    "                #print(\"labels\",labels.shape,labels[0])\n",
    "\n",
    "print(\"finished size\",file_tmp['data/gaf'].shape[0])  \n",
    "print(\"unique labels \",np.unique(grouped_appliances),\"n\",len(grouped_appliances))\n",
    "print(\"counts\",np.unique(file_tmp['labels/gaf'],return_counts=True))\n",
    "print(\"----------------------------------\")\n",
    "\n",
    "asciiList = [n.encode(\"ascii\", \"ignore\") for n in grouped_appliances]\n",
    "print(\"storing\",asciiList,\"n appl\",len(grouped_appliances))\n",
    "\n",
    "group = file_tmp.create_group(\"appliances\")\n",
    "group.create_dataset(\"classes\",np.shape(asciiList),data = asciiList)  \n",
    "\n",
    "file_tmp.close()\n",
    "file_read.close()\n",
    "\n",
    "\n",
    "# print(\"storing appliances \",appliances_list)\n",
    "# print(\"number of images \",images.shape[0])\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...spliting\n",
      "loading labels\n",
      "loading images\n",
      "split shapes shapes:\n",
      "1792\n",
      "449\n",
      "...saving!...\n",
      "storing... samples to store: 1792\n",
      "finshed. stored to iawe_gen_GASF_60m_300S0X_R13_80-20-V1/data/train/gaf\n",
      "storing... samples to store: 1792\n",
      "finshed. stored to iawe_gen_GASF_60m_300S0X_R13_80-20-V1/labels/train/gaf\n",
      "storing... samples to store: 449\n",
      "finshed. stored to iawe_gen_GASF_60m_300S0X_R13_80-20-V1/labels/test/gaf\n",
      "storing... samples to store: 449\n",
      "finshed. stored to iawe_gen_GASF_60m_300S0X_R13_80-20-V1/data/test/gaf\n",
      "...spliting\n",
      "loading labels\n",
      "loading images\n",
      "split shapes shapes:\n",
      "1792\n",
      "449\n",
      "...saving!...\n",
      "storing... samples to store: 1792\n",
      "finshed. stored to iawe_gen_GASF_60m_300S0X_R43_80-20-V1/data/train/gaf\n",
      "storing... samples to store: 1792\n",
      "finshed. stored to iawe_gen_GASF_60m_300S0X_R43_80-20-V1/labels/train/gaf\n",
      "storing... samples to store: 449\n",
      "finshed. stored to iawe_gen_GASF_60m_300S0X_R43_80-20-V1/labels/test/gaf\n",
      "storing... samples to store: 449\n",
      "finshed. stored to iawe_gen_GASF_60m_300S0X_R43_80-20-V1/data/test/gaf\n",
      "...spliting\n",
      "loading labels\n",
      "loading images\n",
      "split shapes shapes:\n",
      "1792\n",
      "449\n",
      "...saving!...\n",
      "storing... samples to store: 1792\n",
      "finshed. stored to iawe_gen_GASF_60m_300S0X_R83_80-20-V1/data/train/gaf\n",
      "storing... samples to store: 1792\n",
      "finshed. stored to iawe_gen_GASF_60m_300S0X_R83_80-20-V1/labels/train/gaf\n",
      "storing... samples to store: 449\n",
      "finshed. stored to iawe_gen_GASF_60m_300S0X_R83_80-20-V1/labels/test/gaf\n",
      "storing... samples to store: 449\n",
      "finshed. stored to iawe_gen_GASF_60m_300S0X_R83_80-20-V1/data/test/gaf\n"
     ]
    }
   ],
   "source": [
    "seeds = [\"13\",\"43\",\"83\"]\n",
    "\n",
    "for seed in seeds:\n",
    "    #train test split\n",
    "    print(\"...spliting\")\n",
    "    file_name_read= \"iawe_gen_GASF_60m_300S0X\"\n",
    "    file_name = file_name_read+\"_R\"+seed+\"_80-20-V1\"\n",
    "   \n",
    "    file_read = h5py.File(\"D:/jjenko/nilm data/GAF_DS/\"f\"{file_name_read}\"\".hdf5\",\"r\")\n",
    "\n",
    "    print(\"loading labels\")\n",
    "    Y = file_read[\"labels/gaf\"][:]\n",
    "    print(\"loading images\")\n",
    "    #X =  file_read[\"data/gaf\"]\n",
    "\n",
    "    #X_i = list(range(X.shape[0]))\n",
    "\n",
    "    #x_ids = list(range(len(X)))\n",
    "\n",
    "    x_train, x_test, Y_train, Y_test = train_test_split(file_read[\"data/gaf\"][:],Y,test_size=0.2,random_state=int(seed),stratify=Y)\n",
    "    print(\"split shapes shapes:\")\n",
    "\n",
    "    print(len(x_train))\n",
    "    print(len(x_test))\n",
    "\n",
    "    print(\"...saving!...\")\n",
    "    store_many_hdf5(x_train,\"data/train\",\"gaf\",force_del=\"yes\")\n",
    "    x_train = 0\n",
    "\n",
    "    store_many_hdf5(Y_train,\"labels/train\",\"gaf\",force_del=\"yes\",label=True)\n",
    "\n",
    "    store_many_hdf5(Y_test,\"labels/test\",\"gaf\",force_del=\"yes\",label=True)\n",
    "\n",
    "    # images =  file_tmp[\"data/tmp/gaf\"]\n",
    "\n",
    "    store_many_hdf5(x_test,\"data/test\",\"gaf\",force_del=\"yes\")\n",
    "\n",
    "    #asciiList = [n.encode(\"ascii\", \"ignore\") for n in appliances_set]\n",
    "    asciiList = file_read[\"appliances/classes\"][:]\n",
    "    store_single_hdf5(asciiList,\"classes\",\"appliances\")\n",
    "\n",
    "    file_read.close()\n",
    "\n",
    "    Y = 0\n",
    "    x_train = 0\n",
    "    x_test = 0\n",
    "    Y_train = 0\n",
    "    Y_Test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading h5 file \n",
    "#file_name = \"REFIT_GASF_13m_100S10X_9A7858N_AB_N-O_Y-S\"\n",
    "#file_name = \"ECO_GASF_13m_100S10X_6A3872N_AB_N-O_Y-S\"\n",
    "#file_name = \"UK-DALE_GASF_13m_100S10X_9A5000N_YmB\"\n",
    "file_name = \"UK-DALE_LIGHTS_GASF_13m_100S10X_1A2287N_AB_N-O_Y-S_AVG-Y\"\n",
    "#file_name = \"AVG_REFIT+ECO+UKDALE+IAWE_GASF_13m_100S10X_1A1000N_2B_N-O_Y-S\"\n",
    "path = \"D:/jjenko/nilm data/GAF_DS/\"\n",
    "#read the file\n",
    "file = h5py.File(f\"{path}\"\"/\"f\"{file_name}\"\".hdf5\", \"r+\")\n",
    "#fetch array of appliances\n",
    "enc_appliances = np.array(file[\"classes/appliances\"])\n",
    "appliances  = [n.decode(\"utf-8\") for n in enc_appliances]\n",
    "\n",
    "print(appliances)\n",
    "\n",
    "weights = np.array(file[\"classes/weights\"])\n",
    "\n",
    "# UK-DALE_GASF_13m_100S10X_10A1856N_AB_N-O_Y-S_AVG-Y\n",
    "\n",
    "train_data = np.array(file[\"data/gasf\"])\n",
    "label_data = np.array(file[\"labels/gaf\"])\n",
    "label_data_buildings = np.array(file[\"labels/building\"])\n",
    "print(\"labels unique\", np.unique(label_data))\n",
    "print(\"labels\",label_data.shape)\n",
    "print(\"building labels\",label_data.shape)\n",
    "print(\"train data shape:\",train_data.shape)\n",
    "file.close()\n",
    "\n",
    "# common_appliances = []\n",
    "\n",
    "# selected for average \n",
    "# iawe iAWE_GASF_13m_100S10X_4A628N_AB_N-O_Y-S_AVG-Y\n",
    "# ukdale \"UK-DALE_GASF_13m_100S10X_10A1856N_AB_N-O_Y-S_AVG-Y\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import second dataset\n",
    "file_name = \"REDD_GASF_13m_100S5X_6A2284N_AB_N-O_Y-S_AVG-Y\"\n",
    "#read the file\n",
    "file = h5py.File(f\"{path}\"\"/\"f\"{file_name}\"\".hdf5\", \"r+\")\n",
    "#fetch array of appliances\n",
    "enc_appliances2 = np.array(file[\"classes/appliances\"])\n",
    "\n",
    "appliances2  = [n.decode(\"utf-8\") for n in enc_appliances2]\n",
    "\n",
    "print(appliances2)\n",
    "\n",
    "weights2 = np.array(file[\"classes/weights\"])\n",
    "\n",
    "train_data2 = np.array(file[\"data/gasf\"])\n",
    "label_data2 = np.array(file[\"labels/gaf\"])\n",
    "label_data_buildings2 = np.array(file[\"labels/building\"])\n",
    "print(\"labels unique\", np.unique(label_data2))\n",
    "print(\"labels\",label_data2.shape)\n",
    "print(\"building labels\",label_data2.shape)\n",
    "print(\"train data shape:\",train_data2.shape)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"labels unique\", np.unique(label_data))\n",
    "print(\"labels\",label_data.shape)\n",
    "print(\"building labels\",label_data.shape)\n",
    "print(\"train data shape:\",train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## script for removing appliances \n",
    "appliances = ['washing machine', 'television',\"microwave\", 'fridge freezer', 'dish washer', 'kettle', 'fridge', 'computer', 'toaster']\n",
    "manualy_selected_appliances = ['washing machine', 'television', 'fridge freezer', 'dish washer', 'computer']\n",
    "\n",
    "# data2 = np.empty_like(train_data)\n",
    "# labels2 = np.empty_like(label_data)\n",
    "# building2 = np.empty_like(label_data_buildings)\n",
    "\n",
    "data2 = np.empty([0,10,100,100,1])\n",
    "labels2 = np.empty(0)\n",
    "building2 = np.empty(0)\n",
    "weights2 = np.empty(0)\n",
    "\n",
    "for appliance in manualy_selected_appliances:\n",
    "    data2 = np.append(data2,train_data[np.where(label_data==appliances.index(appliance))],axis=0)\n",
    "    labels2 = np.append(labels2,label_data[np.where(label_data==appliances.index(appliance))],axis=0)\n",
    "    building2 = np.append(building2,label_data_buildings[np.where(label_data==appliances.index(appliance))],axis=0)\n",
    "    weights2 = np.append(weights2,[weights[appliances.index(appliance)]],axis=0)\n",
    "\n",
    "#labels are not monotonically increasing due to removed labels. Algorithm re-arranges them \n",
    "while np.all(np.diff(np.unique(labels2))==1) == False :\n",
    "    print(np.unique(labels2))\n",
    "    last_index = 0\n",
    "    for index in np.unique(labels2):\n",
    "        \n",
    "        if index-last_index > 1:\n",
    "            \n",
    "            labels2[np.where(labels2 == index)] = index-1\n",
    "        \n",
    "        last_index = index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataset \n",
    "# train_data = data2\n",
    "# label_data = labels2\n",
    "# label_data_buildings = building2\n",
    "# weights = weights2\n",
    "\n",
    "# finished, store the images    \n",
    "file_name = create_file(\"REFIT+ECO\",13,train_data.shape[0],100,10,appliances,ts_save=\"N\",trs_type=\"GASF\",trs_type_gaf=\"GAF\",n_buildings=3,\n",
    "multiple_buildings=\"Y\",selected_building=2,overlap_images=\"N\",overlap_images_by_n=0)\n",
    "\n",
    "\n",
    "store_many_hdf5(train_data,\"data\",\"gasf\",force_del=\"yes\")\n",
    "store_many_hdf5(label_data,\"labels\",\"gaf\",force_del=\"yes\",label=True)\n",
    "store_many_hdf5(label_data_buildings,\"labels\",\"building\",force_del=\"yes\",label=True)\n",
    "\n",
    "\n",
    "asciiList = [n.encode(\"ascii\", \"ignore\") for n in appliances]\n",
    "store_single_hdf5(asciiList,\"appliances\",\"classes\")\n",
    "printLog(\"appliances stored: \", appliances)\n",
    "print(\"appliances stored: \", appliances)\n",
    "store_single_hdf5(weights,\"weights\", \"classes\")\n",
    "printLog(\"weights stored: \", weights)\n",
    "print(\"weights stored: \", weights) #2367.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load dataset hierar\n",
    "##script to read hierarchical format (used in colab)\n",
    "data = np.empty([0,10,100,100,1])\n",
    "\n",
    "labels = np.empty(0)\n",
    "labels_ds = np.empty(0)\n",
    "labels_buildings = np.empty(0)\n",
    "\n",
    "datasets = [\"eco\",\"refit\",\"iawe\",\"ukdale\",\"redd\"]\n",
    "#datasets = [\"eco\",\"refit\"]\n",
    "\n",
    "#appliances = [\"computer\",\"fridge\",\"television\"]\n",
    "appliances = ['HTPC', 'coffee maker', 'computer', 'freezer', 'fridge', 'lamp', 'laptop computer', 'microwave', 'dish washer', 'fridge freezer', 'kettle', 'television', 'toaster', 'washing machine', 'boiler', 'computer monitor','light']\n",
    "\n",
    "for dataset in datasets:\n",
    "\n",
    "  for appliance in file[dataset].keys():\n",
    "      \n",
    "      if appliance in appliances:\n",
    "        print(appliance)\n",
    "        #appliances = appliances.append(appliance)\n",
    "      \n",
    "        for building in file[f\"{dataset}\"\"/\"f\"{appliance}\"\"/\"].keys():\n",
    "            \n",
    "\n",
    "            #if building == 1:\n",
    "              #add code here to skip appliances \n",
    "\n",
    "              images = np.array(file[f\"{dataset}\"\"/\"f\"{appliance}\"\"/\"f\"{building}\"]['gaf'])\n",
    "              \n",
    "              #images = images[0:40,...]\n",
    "              #data = np.append(data,images,axis=0)\n",
    "              \n",
    "              array_of_labels = np.ones(images.shape[0])*appliances.index(appliance)\n",
    "              labels = np.append(labels,array_of_labels)\n",
    "\n",
    "              array_of_labels_ds =  np.ones(images.shape[0])*datasets.index(dataset)\n",
    "              labels_ds = np.append(labels_ds,array_of_labels_ds)\n",
    "\n",
    "              array_of_labels_buildings =  np.ones(images.shape[0])*int(building)\n",
    "              labels_buildings = np.append(labels_buildings,array_of_labels_buildings)\n",
    "\n",
    "              \n",
    "\n",
    "              print(\"dataset\",dataset,\"app\",appliance,\"bui\",building,\"shape\",data.shape,\"labels\",labels.shape,\"dsshape\",labels_ds.shape)\n",
    "\n",
    "        \n",
    "\n",
    "print(np.unique(labels))\n",
    "print(\"dataset: \",np.unique(labels_ds))\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "print(labels_ds.shape)\n",
    "\n",
    "print(labels)\n",
    "#print([key for key in file[\"data\"].keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels_buildings[np.logical_and(np.where(labels == appliances.index(\"washing machine\")),np.where(labels == appliances.index(\"washing machine\")))[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for appliance in appliances:\n",
    "    print(\"appliance\",appliance,\" len\", np.shape(np.where(labels == appliances.index(appliance)))[1])\n",
    "    for dataset in datasets:\n",
    "        appl_building_array = np.unique(labels_buildings[np.where(np.logical_and(labels == appliances.index(appliance),labels_ds == datasets.index(dataset)))])\n",
    "        print(dataset, appl_building_array)\n",
    "\n",
    "        for building in appl_building_array:\n",
    "            print(\"building\",int(building),\"len of data\",np.shape(np.where(np.logical_and(labels_buildings == int(building),labels == appliances.index(appliance))))[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for appliance in appliances:\n",
    "    print(\"appliance: \",appliance,\" len of data: \",np.shape(np.where(labels == appliances.index(appliance)))[1],\" uniq buildings\", np.unique(labels_buildings[np.where(labels == appliances.index(appliance))]),\" uniq datasets \", np.unique(labels_ds[np.where(labels == appliances.index(appliance))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for key in file[\"ukdale\"].keys():\n",
    "    \n",
    "    arr = arr.append(str(key))\n",
    "    print(arr,key)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.array(file[\"redd/microwave/1/gaf\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_appl = list(file[\"eco\"].keys())+list(file[\"refit\"].keys())+list(file[\"ukdale\"].keys())+list(file[\"iawe\"].keys())+list(file[\"redd\"].keys())\n",
    "seen = set()\n",
    "uniq = []\n",
    "dupl = []\n",
    "#con_appl = ['computer', 'fridge', 'microwave', 'freezer', 'fridge', 'fridge freezer', 'kettle', 'laptop computer', 'television', 'computer', 'fridge', 'television', 'air conditioner', 'dish washer', 'fridge', 'microwave', 'washer dryer']\n",
    "for x in con_appl:\n",
    "    if x not in seen:\n",
    "        uniq.append(x)\n",
    "        seen.add(x)\n",
    "    else:\n",
    "        dupl.append(x)\n",
    "\n",
    "print(\"uniq: \", uniq )\n",
    "print(\"dupl: \",dupl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(file[\"refit\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_appl = list(file[\"eco\"].keys())+list(file[\"refit\"].keys())+list(file[\"ukdale\"].keys())+list(file[\"iawe\"].keys())\n",
    "appliances_unique = list([\"test\",\"test2\"])\n",
    "appliances_dupl = []\n",
    "for appliance in con_appl:\n",
    "    print(appliances_unique)\n",
    "    if appliance in appliances_unique:\n",
    "        appliance_dupl = appliances_dupl.append(appliance)\n",
    "    else:\n",
    "        appliances_unique = appliances_unique.append(appliance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##script to read hierarchical format (used in colab)\n",
    "data_lab = np.empty([0,10,100,100,1])\n",
    "labels_lab = np.empty(0)\n",
    "label_index = 0\n",
    "appliances_lab = []\n",
    "\n",
    "for appliance in file[\"refit/\"].keys():\n",
    "    \n",
    "    \n",
    "    for building in file[\"refit/\"f\"{appliance}\"\"/\"].keys():\n",
    "        \n",
    "        #add code here to skip appliances \n",
    "\n",
    "        images = np.array(file[\"refit/\"f\"{appliance}\"\"/\"f\"{building}\"]['gaf'])\n",
    "        data_lab = np.append(data_lab,images,axis=0)\n",
    "        \n",
    "        array_of_labels = np.ones(images.shape[0])*label_index\n",
    "        labels_lab = np.append(labels_lab,array_of_labels)\n",
    "\n",
    "        print(\"app\",appliance,\"bui\",building,\"shape\",data_lab.shape,\"labels\",labels_lab.shape)\n",
    "\n",
    "    appliances_lab.append(appliance)\n",
    "    label_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appliances = []\n",
    "for ds in file.keys():\n",
    "    if ds == \"ukdale\":\n",
    "        for appliance in file[ds].keys():\n",
    "            if appliance == \"microwave\":\n",
    "                for building in file[ds][appliance].keys():\n",
    "                    \n",
    "                    print(np.array(file[ds][appliance][building][\"gaf\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO \n",
    "#parse old dataset and save it in more standard manor (hierar):\n",
    "#datasets = [eco, refit]\n",
    "file_name= \"ALL_13m_100S10X_Y-S_AVG-Y\"\n",
    "\n",
    "#file_name = create_file(\"AVG_ALL\",13,1000,100,10,[\"appliances\"],ts_save=\"N\",trs_type=\"GASF\",trs_type_gaf=\"GAF\",n_buildings=3,\n",
    "#multiple_buildings=\"Y\",selected_building=2,overlap_images=\"N\",overlap_images_by_n=0)\n",
    "\n",
    "dataset = \"ukdale\"\n",
    "#for dataset in datasets:\n",
    "for appliance in appliances:\n",
    "    for building in range(1,int(max(label_data_buildings))+1):\n",
    "        group_path = f\"{dataset}\"\"/\"f\"{appliance}\"\"/\"f\"{building}\"\"\"\n",
    "        images = train_data[np.where(np.logical_and(label_data==appliances.index(appliance),label_data_buildings==building))]\n",
    "\n",
    "        if images.shape[0] > 0:\n",
    "            store_many_hdf5(images,group_path,\"gaf\",force_del=\"yes\")\n",
    "        else:\n",
    "            print(\"empty for building\",building,\"appliance\",appliance)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--PARAMTERS--#\n",
    "\n",
    "#-step\n",
    "step_in_mins = 13\n",
    "#-image\n",
    "max_dataset_size =  1500 #max number of images per appliance per buidling \n",
    "img_size = 100 # means img_size x img_size (igored when using RECC)\n",
    "n_of_multi_dim_imgs = 10 #change to 0 for normal images (read overlap)\n",
    "\n",
    "#-samples\n",
    "sample_period = 6 # cm be obtained from dataset.metadata[\"sample_period\"] but it is inconsistent\n",
    "percentage_of_missing_data_allowed = 0.73 # is necessary since sampling rate is inconsistent or samples are missing \n",
    "\n",
    "#-brightness\n",
    "add_brightness = True\n",
    "\n",
    "#-timeseries\n",
    "ts_save = \"N\" # \"Y\" - save soruce time-series data to output GAF dataset. \"N\" - do not save ts data\n",
    "ts_size = round(step_in_mins*60/sample_period) # calculate estimate size of ts\n",
    "\n",
    "#-trans type\n",
    "trs_type = \"GAF\" #GAF or RECU - Gramian Angural Field or Recurrance plot\n",
    "\n",
    "#-if trans type GAF \n",
    "trs_type_gaf = \"GASF\" # GASF or GADF\n",
    "\n",
    "#-overlap images (read comments bellow!)\n",
    "overlap_images = False #True or false \n",
    "overlap_images_by_n = 0 #how many images should overlap  **will make n_of_multi_dim_imags shorter by overlap_image_by_n!!!***\n",
    "\n",
    "if overlap_images==False : overlap_images_by_n = 0; # safety! \n",
    "\n",
    "#-buildings\n",
    "n_buildings = 3\n",
    "multiple_buildings = \"Y\" # multiple buildings Y on N\n",
    "selected_building = 5 # is used in case parameter multiple buidlings is N\n",
    "\n",
    "if multiple_buildings == \"Y\":\n",
    "    selected_building = \"A\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printLog(*args, **kwargs):\n",
    "    #print(*args, **kwargs)\n",
    "    with open('D:/jjenko/nilm data/GAF_DS/output.txt','a') as file:\n",
    "        print(*args, **kwargs, file=file)\n",
    "\n",
    "def create_file(dataset_name,step_in_mins,dataset_size,img_size,n_of_multi_dim_imgs,appliances,**kwargs):\n",
    "    \n",
    "    #cell is responsible for storing and handling with hdf5 data\n",
    "    #if file does not exist create new one (M-n of months A-n of appliances)\n",
    "    #file_name = \"UKDALE_GAF_1h_12M10A300N\"\n",
    "    ts_save = kwargs.get('ts_save', None)\n",
    "    trs_type = kwargs.get('trs_type', None)\n",
    "    overlap_images = kwargs.get('overlap_images', None)\n",
    "    overlap_images_by_n = kwargs.get('overlap_images_by_n', None)\n",
    "    trs_type_gaf = kwargs.get('trs_type_gaf', None)\n",
    "    n_buildings = kwargs.get('n_buildings',None)\n",
    "    multiple_buildings = kwargs.get('multiple_buildings', None)\n",
    "    selected_building = kwargs.get('selected_building', None)\n",
    "\n",
    "    if overlap_images == True:\n",
    "        overlap_images_str=\"Y\"\n",
    "    else:\n",
    "        overlap_images_str=\"N\"\n",
    "\n",
    "\n",
    "    if trs_type == \"GAF\":\n",
    "        trs_type = trs_type_gaf\n",
    "\n",
    "    if ts_save == \"Y\":\n",
    "        file_name =f\"{dataset_name}\"\"_\"f\"{trs_type}\"\"_\"f\"{step_in_mins}\"\"m_\"f\"{img_size}\"\"S\"f\"{n_of_multi_dim_imgs-overlap_images_by_n}\"\"X_\"f\"{ts_save}\"\"-TS_\"f\"{len(appliances)}\"\"A\"f\"{dataset_size}\"\"N_\"f\"{selected_building}B\"\"_\"f\"{overlap_images_str}\"\"-O_Y-S\"\n",
    "    else:\n",
    "        file_name =f\"{dataset_name}\"\"_\"f\"{trs_type}\"\"_\"f\"{step_in_mins}\"\"m_\"f\"{img_size}\"\"S\"f\"{n_of_multi_dim_imgs-overlap_images_by_n}\"\"X_\"f\"{len(appliances)}\"\"A\"f\"{dataset_size}\"\"N_\"f\"{selected_building}B\"\"_\"f\"{overlap_images_str}\"\"-O_Y-S\"\n",
    "\n",
    "    #check if file exists\n",
    "    try:\n",
    "        file = h5py.File(\"D:/jjenko/nilm data/GAF_DS/\"f\"{file_name}\"\".hdf5\",\"r\")\n",
    "        print(\"file exists!\")\n",
    "        file.close()\n",
    "\n",
    "    except:\n",
    "        print(\"creating new file! ...\")\n",
    "        file = h5py.File(\"D:/jjenko/nilm data/GAF_DS/\"f\"{file_name}\"\".hdf5\", \"w\")\n",
    "\n",
    "        group = file.create_group(\"classes\")\n",
    "        \n",
    "        file.close()\n",
    "\n",
    "   \n",
    "\n",
    "    return file_name\n",
    "\n",
    "def create_hdf5_group(group_name,id): #groups are appliances such as fridge or toaster\n",
    "\n",
    "    file = h5py.File(\"D:/jjenko/nilm data/GAF_DS/\"f\"{file_name}\"\".hdf5\", \"a\")\n",
    "    file.create_group(f\"{group_name}\")\n",
    "    file.close()\n",
    "\n",
    "    return file\n",
    "\n",
    "\n",
    "def store_single_hdf5(data, file_id, group_name): \n",
    "    \"\"\"\n",
    "    Stores single image to HDF5\n",
    "    \"\"\"     \n",
    "    # read HDF5 file\n",
    "    try:\n",
    "        file = h5py.File(\"D:/jjenko/nilm data/GAF_DS/\"f\"{file_name}\"\".hdf5\", \"a\")\n",
    "    except:\n",
    "        print(\"file not found!\")\n",
    "    \n",
    "    # open specified group\n",
    "    try:\n",
    "        group = file[f\"{group_name}\"]\n",
    "    except:\n",
    "        #if if does not exist create it\n",
    "        group = file.create_group(f\"{group_name}\")\n",
    "\n",
    "    \n",
    "    try:\n",
    "        group.create_dataset(f\"{file_id}\",np.shape(data),data = data)  \n",
    "    except:\n",
    "        del group[f\"{file_id}\"]\n",
    "        group.create_dataset(f\"{file_id}\",np.shape(data),data = data)\n",
    "        print(\"  replaced \"f\"{file_id}\"\"!\")\n",
    "   \n",
    "    file.close()\n",
    "\n",
    "def store_many_hdf5(images,group_name,image_set_name,**kwargs):\n",
    "    \"\"\"\n",
    "    Stores multiple images to HDF5\n",
    "    **kwargs(force_del=\"yes\" to replace existing db w/o prompt)\n",
    "    \"\"\"     \n",
    "    #define some parameters\n",
    "    num_images = len(images)\n",
    "    force_del_flag = kwargs.get('force_del', None)# we need it, if \"store many\" is frequently called\n",
    "    \n",
    "    label_flag = kwargs.get('labels', None)# we need it, if \"store many\" is frequently called\n",
    "\n",
    "    # read HDF5 file\n",
    "    try:\n",
    "        file = h5py.File(\"D:/jjenko/nilm data/GAF_DS/\"f\"{file_name}\"\".hdf5\", \"a\")\n",
    "    except:\n",
    "        print(\"file not found!\")\n",
    "    \n",
    "    \n",
    "    # open specified group\n",
    "    try:\n",
    "        group = file[f\"{group_name}\"]\n",
    "    except:\n",
    "        #if if does not exist create it\n",
    "        group = file.create_group(f\"{group_name}\")\n",
    "\n",
    "        #subgroup = \n",
    "        \n",
    "     \n",
    "    #check if ds already exists, then prompt user\n",
    "    for name in group:\n",
    "        if str(name) == str(image_set_name):\n",
    "            if force_del_flag == \"yes\":\n",
    "                print(\"  removed \"f\"{name}\"\"!\")   \n",
    "                del group[name]\n",
    "            else:\n",
    "                print(\"Dataset '\"f\"{name}\" \"' already exists in \" f\"{file_name}\"\"/\"f\"{group_name}\")\n",
    "                \n",
    "                ans = input(\"Do you want to replace existing dataset? (y,n) Press enter to contine\")\n",
    "                    \n",
    "                if ans == \"y\":\n",
    "                    print(\"  removed \"f\"{name}\"\"!\")   \n",
    "                    del group[name]\n",
    "                else:\n",
    "                    print(\"  quiting! \") \n",
    "                    raise\n",
    "\n",
    "    # Create a dataset in the group       \n",
    "    print(\"storing... samples to store: \"f\"{num_images}\")\n",
    "    \n",
    "    if label_flag == True:\n",
    "        #save labels as integers. If sentence needed in case no labels are provided\n",
    "        dataset = group.create_dataset(f\"{image_set_name}\", np.shape(images), h5py.h5t.H5T_STD_I8BE , data=images)\n",
    "    else:\n",
    "        dataset = group.create_dataset(f\"{image_set_name}\", np.shape(images), h5py.h5t.IEEE_F32LE , data=images)\n",
    "    \n",
    "    file.close()\n",
    "    print(\"finshed. stored to \" f\"{file_name}\"\"/\"f\"{group_name}\"\"/\"f\"{image_set_name}\")\n",
    "\n",
    "\n",
    "def read_many_hdf5(group_name,image_set_name):\n",
    "    \"\"\" \n",
    "    Reads image from HDF5.\n",
    "\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    file = h5py.File(\"D:/jjenko/nilm data/GAF_DS/\"f\"{file_name}\"\".hdf5\", \"r+\")\n",
    "\n",
    "    images = np.array(file[f\"{group_name}\"\"/\"f\"{image_set_name}\"])\n",
    "\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-14e87bd077c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#script adds appliances to first dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmax_label_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mlabel_data2\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmax_label_num\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'label_data' is not defined"
     ]
    }
   ],
   "source": [
    "#script for joining datasets\n",
    "#script adds appliances to first dataset \n",
    "\n",
    "max_label_num = max(label_data)+1\n",
    "label_data2 += max_label_num\n",
    "\n",
    "print(\"appending ...\")\n",
    "\n",
    "appliances_tmp = appliances\n",
    "\n",
    "for appliance in appliances2:\n",
    "    \n",
    "    #if appliances between two datasets are common \n",
    "    if any(np.isin(appliances,appliance)):\n",
    "        print(\"common appliance:\",appliance)\n",
    "        common_appliances.append(appliance)\n",
    "        #get appliance indexes\n",
    "        index_appl = appliances.index(appliance)\n",
    "        #re-label appliances to same index as main dataset\n",
    "        label_data2[np.where(label_data2==(appliances2.index(appliance)+max_label_num))] = index_appl\n",
    "        #append appliances with new indexes \n",
    "        label_data = np.append(label_data,label_data2[np.where(label_data2==index_appl)],axis=0)\n",
    "        train_data = np.append(train_data,train_data2[np.where(label_data2==index_appl)],axis=0)\n",
    "        label_data_buildings = np.append(label_data_buildings,label_data_buildings2[np.where(label_data2==index_appl)],axis=0)\n",
    "\n",
    "    else:\n",
    "        #append as normal \n",
    "        print(appliance)\n",
    "        label_data = np.append(label_data,label_data2[np.where(label_data2==appliances2.index(appliance)+max_label_num)],axis=0)   \n",
    "        train_data = np.append(train_data,train_data2[np.where(label_data2==appliances2.index(appliance)+max_label_num)],axis=0)\n",
    "        label_data_buildings = np.append(label_data_buildings,label_data_buildings2[np.where(label_data2==appliances2.index(appliance)+max_label_num)],axis=0)\n",
    "        appliances_tmp.append(appliance)\n",
    "    \n",
    "    weights = np.append(weights,[weights2[appliances2.index(appliance)]],axis=0)\n",
    "    \n",
    "\n",
    "print(\"... done appending\")\n",
    "\n",
    "#labels are not monotonically increasing due to relabeled labels. Algorithm re-arranges them \n",
    "print(\"re-ordering ...\")\n",
    "while np.all(np.diff(np.unique(label_data))==1) == False :\n",
    "   \n",
    "    print(np.unique(label_data))\n",
    "    last_index = 0\n",
    "    for index in np.unique(label_data):\n",
    "        \n",
    "        if index-last_index > 1:\n",
    "            \n",
    "            label_data[np.where(label_data == index)] = index-1\n",
    "        \n",
    "        last_index = index\n",
    "\n",
    "#store new appliances\n",
    "\n",
    "appliances = appliances_tmp\n",
    "\n",
    "#because of new data, calculate new weights \n",
    "weights = np.empty(0)\n",
    "for appliance in appliances:\n",
    "    weights = np.append(weights,[train_data[np.where(label_data==appliances.index(appliance))].shape[0]],axis=0)\n",
    "    \n",
    "weights = np.round(weights/max(weights),3)\n",
    "\n",
    "\n",
    "print(\"... done!\")\n",
    "print(\"labels unique\", np.unique(label_data))\n",
    "print(\"labels\",label_data.shape)\n",
    "print(\"building labels\",label_data_buildings.shape)\n",
    "print(\"train data shape:\",train_data.shape)\n",
    "print(\"weights\",weights)\n",
    "print(appliances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##long function for sorting appliances\n",
    "\n",
    "def get_grouped_appliances(available_appliances,dataset):\n",
    "\n",
    "    if dataset[0] == \"refit\":\n",
    "        \n",
    "        HEKA = [\"toaster\",\"kettle\"]\n",
    "        FF = [\"fridge\",\"fridge freezer\"]\n",
    "        grouped_appliances = {\n",
    "            \n",
    "            \"HEKA\":HEKA,\n",
    "            \"fridge/freezer\":FF,\n",
    "            \n",
    "        } \n",
    "        #not enough data for this appliance\n",
    "\n",
    "        available_appliances.remove(\"fan\")\n",
    "        available_appliances.remove(\"games console\")\n",
    "        available_appliances.remove(\"unknown\")\n",
    "        available_appliances.remove(\"appliance\")\n",
    "\n",
    "        # #new group\n",
    "        available_appliances.remove(\"fridge\")\n",
    "        available_appliances.remove(\"fridge freezer\")\n",
    "\n",
    "        #new group\n",
    "        available_appliances.remove(\"toaster\")\n",
    "        available_appliances.remove(\"kettle\")\n",
    "\n",
    "        ##radndom out\n",
    "        #available_appliances.remove(\"computer\")\n",
    "        available_appliances.remove(\"microwave\")\n",
    "        #available_appliances.remove(\"washer dryer\")\n",
    "\n",
    "        #available_appliances.remove(\"washing machine\")\n",
    "        #available_appliances.remove(\"microwave\")\n",
    "        #available_appliances.remove(\"microwave\")\n",
    "\n",
    "        #for one case only\n",
    "\n",
    "        #all else are the same\n",
    "        for a in available_appliances:\n",
    "            grouped_appliances[a] = [a]\n",
    "\n",
    "    if dataset[0] == \"redd\":\n",
    "        HEKA = []\n",
    "        FF = [\"fridge\"]\n",
    "        grouped_appliances = {\"fridge/freezer\":FF}\n",
    "        available_appliances.remove(\"electric stove\")\n",
    "        available_appliances.remove(\"washer dryer\")\n",
    "        available_appliances.remove(\"dish washer\")\n",
    "        available_appliances.remove(\"electric oven\")\n",
    "        available_appliances.remove(\"air conditioner\")\n",
    "        available_appliances.remove(\"air handling unit\")\n",
    "        available_appliances.remove(\"electric space heater\")\n",
    "        available_appliances.remove(\"fridge\")\n",
    "        for a in available_appliances:\n",
    "            grouped_appliances[a] = [a]\n",
    "\n",
    "    if dataset[0] == \"eco\":\n",
    "        HEKA = [\"kettle\"]\n",
    "        FF = [\"fridge\",\"freezer\"]\n",
    "        grouped_appliances = {\n",
    "            \n",
    "            \"HEKA\":HEKA,\n",
    "            \"fridge/freezer\":FF,\n",
    "            \n",
    "        } \n",
    "        #not enough data for this appliance\n",
    "        available_appliances.remove(\"garden sprinkler\")\n",
    "\n",
    "        available_appliances.remove(\"air handling unit\")\n",
    "        available_appliances.remove(\"dish washer\")\n",
    "        # #new group\n",
    "        available_appliances.remove(\"fridge\")\n",
    "        \n",
    "        available_appliances.remove(\"freezer\")\n",
    "\n",
    "        #new group\n",
    "\n",
    "        available_appliances.remove(\"kettle\")\n",
    "\n",
    "        #for one case only\n",
    "\n",
    "        #all else are the same\n",
    "        for a in available_appliances:\n",
    "            grouped_appliances[a] = [a]\n",
    "\n",
    "    if dataset[0] == \"ukdale\":\n",
    "        #for ukdale\n",
    "\n",
    "        HEKA = [\"toaster\",\"kettle\"]\n",
    "        FF = [\"fridge\",\"freezer\",\"fridge freezer\"]\n",
    "        grouped_appliances = {\n",
    "            \n",
    "            \"HEKA\":HEKA,\n",
    "            \"fridge/freezer\":FF,\n",
    "            \n",
    "        } \n",
    "        #not enough data for this appliance\n",
    "        available_appliances.remove(\"washing machine\")\n",
    "        available_appliances.remove(\"dish washer\")\n",
    "\n",
    "\n",
    "        # #new group\n",
    "        available_appliances.remove(\"fridge\")\n",
    "        available_appliances.remove(\"freezer\")\n",
    "        available_appliances.remove(\"fridge freezer\")\n",
    "\n",
    "        #new group\n",
    "        available_appliances.remove(\"toaster\")\n",
    "        available_appliances.remove(\"kettle\")\n",
    "\n",
    "        #for one case only\n",
    "\n",
    "        #all else are the same\n",
    "        for a in available_appliances:\n",
    "            grouped_appliances[a] = [a]\n",
    "\n",
    "    if dataset[0] == \"iawe\":\n",
    "        grouped_appliances = {} \n",
    "        available_appliances.remove(\"washing machine\")\n",
    "\n",
    "        for a in available_appliances:\n",
    "            grouped_appliances[a] = [a]\n",
    "            \n",
    "\n",
    "    \n",
    "    return grouped_appliances"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
